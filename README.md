
# Hello, LLM Enthusiast Here! ğŸ‘‹ ğŸ¤–

<div align="center">
    
### Connect & Follow
[![](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/perovicmitar)
[![](https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/permitt_ai)
[![](https://img.shields.io/badge/Hugging%20Face-FFE033?style=for-the-badge&logo=huggingface&logoColor=black)](https://huggingface.co/permitt)

### Content & Blogs
[![](https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtube.com/@permitt_ai)
[![](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@permitt)
[![](https://img.shields.io/badge/Substack-FF6719?style=for-the-badge&logo=substack&logoColor=white)](https://substack.com/@permitt)

</div>

Diving deep into the world of Large Language Models! From architecture exploration to deployment, I'm passionate about understanding and building with these fascinating models. Proud owner of an RTX 4090 that powers my local LLM experiments! ğŸš€

## ğŸ”­ Current Focus
- Exploring various LLM architectures
- Fine-tuning techniques (LoRA, QLoRA, PEFT)
- Building with agentic frameworks (LangGraph, AutoGPT)
- Optimizing inference for consumer GPUs

## ğŸ› ï¸ Tech Stack
- **Core**: Python, PyTorch, Transformers
- **LLM Tools**: 
  - ğŸ¤— Hugging Face ecosystem
  - ğŸ¦œ LangChain, LlamaIndex
  - ğŸš€ vLLM, text-generation-inference
- **Quantization**: bitsandbytes, GPTQ, AWQ
- **Deployment**: FastAPI, Gradio, Docker
- **Hardware**: NVIDIA RTX 4090 (precious âœ¨)

## ğŸŒ± Learning Journey
- Advanced techniques in Prompt Engineering
- Multi-agent systems and autonomous AI
- Knowledge Graphs for RAG (Retrieval-Augmented Generation) optimization
- Model distillation and compression methods
- Vector databases (QDrant, Pinecone)

## ğŸ’¡ Featured Projects
- ğŸ§  **Local LLM Playground**: Optimized inference setup for running open-source LLMs on RTX 4090
- ğŸ¤– **Custom Agent Framework**: Building autonomous agents with specific capabilities
- ğŸ“š **RAG System**: Enhanced retrieval system with custom embeddings






